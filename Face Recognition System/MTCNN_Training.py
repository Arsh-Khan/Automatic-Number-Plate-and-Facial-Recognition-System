# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G1d1FQCdAY2Kh4e6X1GO37FD-B3X65K8
"""

!pip install deepface
!pip install mtcnn
!pip install utils
!pip install keras-facenet
# !pip install sklearn
# !pip install Cython
!pip install scikit-learn scipy matplotlib numpy

!pip install scipy
!pip install scikit-learn

from deepface import DeepFace
# verification = DeepFace.verify(img1_path = "img1.jpg", img2_path = "img2.jpg")
recognition = DeepFace.find(img_path = "drive/MyDrive/test images", db_path = "drive/MyDrive/celeb dataset")

import os
import pickle
import numpy as np
import cv2
import mtcnn
from keras.models import load_model
# from utils import get_face, get_encode, l2_normalizer, normalize

# hyper-parameters
encoder_model = 'drive/MyDrive/keras-facenet/model/facenet_keras.h5'
people_dir = 'data/people'
encodings_path = 'data/encodings/encodings.pkl'
required_size = (160, 160)

face_detector = mtcnn.MTCNN()
face_encoder = load_model(encoder_model)

encoding_dict = dict()

for person_name in os.listdir(people_dir):
    person_dir = os.path.join(people_dir, person_name)
    encodes = []
    for img_name in os.listdir(person_dir):
        img_path = os.path.join(person_dir, img_name)
        img = cv2.imread(img_path)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = face_detector.detect_faces(img_rgb)
        if results:
            res = max(results, key=lambda b: b['box'][2] * b['box'][3])
            face, _, _ = get_face(img_rgb, res['box'])

            face = normalize(face)
            face = cv2.resize(face, required_size)
            encode = face_encoder.predict(np.expand_dims(face, axis=0))[0]
            encodes.append(encode)
    if encodes:
        encode = np.sum(encodes, axis=0)
        encode = l2_normalizer.transform(np.expand_dims(encode, axis=0))[0]
        encoding_dict[person_name] = encode


for key in encoding_dict.keys():
    print(key)

with open(encodings_path, 'bw') as file:
    pickle.dump(encoding_dict, file)

import pickle
import numpy as np
import matplotlib.pyplot as plt
import cv2
from sklearn.preprocessing import Normalizer


# get encode
def get_encode(face_encoder, face, size):
    face = normalize(face)
    face = cv2.resize(face, size)
    encode = face_encoder.predict(np.expand_dims(face, axis=0))[0]
    return encode


def get_face(img, box):
    x1, y1, width, height = box
    x1, y1 = abs(x1), abs(y1)
    x2, y2 = x1 + width, y1 + height
    face = img[y1:y2, x1:x2]
    return face, (x1, y1), (x2, y2)


l2_normalizer = Normalizer('l2')


def normalize(img):
    mean, std = img.mean(), img.std()
    return (img - mean) / std


def plt_show(cv_img):
    img_rgb = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)
    plt.imshow(img_rgb)
    plt.show()


def load_pickle(path):
    with open(path, 'rb') as f:
        encoding_dict = pickle.load(f)
    return encoding_dict


def save_pickle(path, obj):
    with open(path, 'wb') as file:
        pickle.dump(obj, file)


def read_vc(vc, func_to_call, break_print=':(', show=False, win_name='', break_key='q', **kwargs):
    while vc.isOpened():
        ret, frame = vc.read()
        if not ret:
            print(break_print)
            break
        res = func_to_call(frame, **kwargs)
        if res is not None:
            frame = res

        if show:
            cv2.imshow(win_name, frame)
        if cv2.waitKey(1) & 0xff == ord(break_key):
            break

import cv2 as cv
import os
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow
from mtcnn.mtcnn import MTCNN
from keras_facenet import FaceNet
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import pickle
os.environ["TF_CPP_MTN_LOG_LEVEL"] = "2"
img = cv.imread("/content/drive/MyDrive/celeb_dataset/Bill_Clinton/1.jpg")
img2 = cv.cvtColor(img, cv.COLOR_BGR2RGB)
# plt.imshow(img)
detector = MTCNN()
results = detector.detect_faces(img2)
x,y,w,h = results[0]['box']
img3 = cv.rectangle(img2, (x,y), (x+w,y+h), (0,0,225), 3)
# plt.imshow(img)
cv2_imshow(img3)
my_face = img[y:y+h , x:x+w]
my_face = cv.resize(my_face, (160,160))
# plt.imshow(my_face)
cv2_imshow(my_face)

class FACELOADING:
  def __init__(self, directory):
    self.directory = directory
    self.target_size = (160,160)
    self.X = []
    self.Y = []
    self.detector = MTCNN()
  def extract_face(self, filename):
    img = cv.imread(filename)
    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)
    x,y,w,h = self.detector.detect_faces(img)[0]['box']
    x,y = abs(x), abs(y)
    face = img[y:y+h, x:x+w]
    face_arr = cv.resize(face, self.target_size)
    return face_arr
  def load_faces(self, dir):
    FACES = []
    for im_name in os.listdir(dir):
      try:
        path = dir + im_name
        single_face = self.extract_face(path)
        FACES.append(single_face)
      except:
        print("Face not found")
        pass
    return FACES
  def load_classes(self):
        for sub_dir in os.listdir(self.directory):
            path = self.directory +'/'+ sub_dir+'/'
            FACES = self.load_faces(path)
            labels = [sub_dir for _ in range(len(FACES))]
            print(f"Loaded successfully: {len(labels)}")
            self.X.extend(FACES)
            self.Y.extend(labels)
        return np.asarray(self.X), np.asarray(self.Y)
  def plot_images(self):
    # plt.figure(figsize=(18,16))
    for num,image in enumerate(self.X):
      cv2_imshow(image)
      # cv2_imshow(face_arr)
      # ncols = 5
      # nrows = len(self.X)//ncols + 1
      # plt.subplot(nrows,ncols,num+1)
      # plt.imshow(image)
      # plt.axis('off')

faceloading = FACELOADING("/content/drive/MyDrive/celeb_dataset")
X, Y = faceloading.load_classes()
# plt.figure(figsize=(16,12))
for num, image in enumerate(X):
  cv2_imshow(image)
  # cv2_imshow(my_face)
  # ncols = 5
  # nrows = len(Y)//ncols + 1
  # plt.subplot(nrows,ncols,num+1)
  # plt.imshow(image)
  # plt.axis('off')
embedder = FaceNet()
def get_embedding(face_img):
  face_img = face_img.astype('float32')
  face_img = np.expand_dims(face_img, axis=0)
  yhat = embedder.embeddings(face_img)
  return yhat[0]

EMBEDDED_X = []
for img in X:
  EMBEDDED_X.append(get_embedding(img))
EMBEDDED_X = np.asarray(EMBEDDED_X)
np.savez_compressed('faces_embeddings_done_4classes.npz', EMBEDDED_X, Y)

encoder = LabelEncoder()
encoder.fit(Y)
# Y = encoder.transfom(Y)
plt.plot(EMBEDDED_X[0])
plt.ylabel(Y[0])
X_train, X_test, Y_train, Y_test = train_test_split(EMBEDDED_X, Y, shuffle=True, random_state=17)
model = SVC(kernel='linear', probability=True)
model.fit(X_train, Y_train)
ypreds_train = model.predict(X_train)
ypreds_test = model.predict(X_test)
accuracy_score(Y_test, ypreds_test)
t_im = cv.imread("/content/drive/MyDrive/celeb_dataset/Bill_Clinton/10.jpg")
t_im2 = cv.cvtColor(t_im, cv.COLOR_BGR2RGB)
x,y,w,h = detector.detect_faces(t_im2)[0]['box']
t_im3 = t_im2[y:y+h, x:x+w]
t_im4 = cv.resize(t_im3, (160,160))
test_im = get_embedding(t_im)
test_im = [test_im]
ypreds = model.predict(test_im)
with open('svm_model_160x160.pkl','wb') as f:
  pickle.dump(model,f)

import cv2 as cv
import numpy as np
import os
os.environ['TF_CPP_MIN_LOG_LEVEL']='2'
import tensorflow as tf
import pickle
from keras_facenet import FaceNet
from sklearn.preprocessing import LabelEncoder
from google.colab.patches import cv2_imshow

facenet = FaceNet()
faces_embeddings = np.load("faces_embeddings_done_4classes.npz")
Y = faces_embeddings['arr_1']
encoder = LabelEncoder()
encoder.fit(Y)
haarcascade = cv.CascadeClassifier("haarcascade_frontalface_default.xml")
model = pickle.load(open("svm_model_160x160.pkl", 'rb'))
cap = cv.VideoCapture(0)
while cap.isOpened():
  _,frame = cap.read()
  rgb_image = cv.cvtColor(frame, cv.COLOR_BGR2RGB)
  gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
  faces = haarcascade.detectMultiScale(gray, 1.3, 5)
  for x,y,w,h in faces:
    try:
      img = rgb_image[y:y+h, x:x+w]
      img = cv.resize(img, (160,160))
      img = np.expand_dims(img,axis=0)
      ypred = facenet.embeddings(img)
      face_name = model.predict(ypred)
      final_name = encoder.inverse_transforn(face_name)
      cv.rectangle(frame, (x,y), (x+w,y+h), (0,0,255), 10)
      cv.putText(frame, str(final_name), (x,y-10), cv.FONT_HARSHEY_SIMPLEX, 1, (0,0,255), 3, cv.LINE_AA)
    except:
      print("Face not found")
      pass
  cv2_imshow("Face Recognized", frame)

cap.release()